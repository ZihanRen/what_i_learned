{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source： https://github.com/dome272/VQGAN-pytorch/tree/main\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GroupNorm(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(GroupNorm, self).__init__()\n",
    "        self.gn = nn.GroupNorm(num_groups=32, num_channels=channels, eps=1e-6, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gn(x)\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "# Resnet block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.block = nn.Sequential(\n",
    "            GroupNorm(in_channels),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
    "            GroupNorm(out_channels),\n",
    "            Swish(),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "\n",
    "        if in_channels != out_channels:\n",
    "            self.channel_up = nn.Conv2d(in_channels, out_channels, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.in_channels != self.out_channels:\n",
    "            return self.channel_up(x) + self.block(x)\n",
    "        else:\n",
    "            return x + self.block(x)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DownSampleBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DownSampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 2, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pad = (0, 1, 0, 1)\n",
    "        x = F.pad(x, pad, mode=\"constant\", value=0)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class NonLocalBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(NonLocalBlock, self).__init__()\n",
    "        self.in_channels = channels\n",
    "\n",
    "        self.gn = GroupNorm(channels)\n",
    "        self.q = nn.Conv2d(channels, channels, 1, 1, 0)\n",
    "        self.k = nn.Conv2d(channels, channels, 1, 1, 0)\n",
    "        self.v = nn.Conv2d(channels, channels, 1, 1, 0)\n",
    "        self.proj_out = nn.Conv2d(channels, channels, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = self.gn(x)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "\n",
    "        b, c, h, w = q.shape\n",
    "\n",
    "        q = q.reshape(b, c, h*w)\n",
    "        q = q.permute(0, 2, 1)\n",
    "        k = k.reshape(b, c, h*w)\n",
    "        v = v.reshape(b, c, h*w)\n",
    "\n",
    "        attn = torch.bmm(q, k)\n",
    "        attn = attn * (int(c)**(-0.5))\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "        attn = attn.permute(0, 2, 1)\n",
    "\n",
    "        A = torch.bmm(v, attn)\n",
    "        A = A.reshape(b, c, h, w)\n",
    "\n",
    "        return x + A\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, image_channels=1, latent_dim=256):\n",
    "        super(Encoder, self).__init__()\n",
    "        channels = [128, 128, 128, 256, 256, 512]\n",
    "        attn_resolutions = [16]\n",
    "        num_res_blocks = 2\n",
    "        resolution = 256\n",
    "        layers = [nn.Conv2d(image_channels, channels[0], 3, 1, 1)]\n",
    "        for i in range(len(channels)-1):\n",
    "            in_channels = channels[i]\n",
    "            out_channels = channels[i + 1]\n",
    "            for j in range(num_res_blocks):\n",
    "                layers.append(ResidualBlock(in_channels, out_channels))\n",
    "                in_channels = out_channels\n",
    "                if resolution in attn_resolutions:\n",
    "                    layers.append(NonLocalBlock(in_channels))\n",
    "            if i != len(channels)-2:\n",
    "                layers.append(DownSampleBlock(channels[i+1]))\n",
    "                resolution //= 2\n",
    "        layers.append(ResidualBlock(channels[-1], channels[-1]))\n",
    "        layers.append(NonLocalBlock(channels[-1]))\n",
    "        layers.append(ResidualBlock(channels[-1], channels[-1]))\n",
    "        layers.append(GroupNorm(channels[-1]))\n",
    "        layers.append(Swish())\n",
    "        layers.append(nn.Conv2d(channels[-1], latent_dim, 3, 1, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder output\n",
    "\n",
    "* a 8*8 square latent space where each node is (1,256)\n",
    "* elements: groupnorm, resnet, Swish activation func, nonlocal block (attention layer to extract global long distance dependent features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoder architecture is\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Encoder                                       [1, 256, 8, 8]            --\n",
      "├─Sequential: 1-1                             [1, 256, 8, 8]            --\n",
      "│    └─Conv2d: 2-1                            [1, 128, 128, 128]        1,280\n",
      "│    └─ResidualBlock: 2-2                     [1, 128, 128, 128]        --\n",
      "│    │    └─Sequential: 3-1                   [1, 128, 128, 128]        295,680\n",
      "│    └─ResidualBlock: 2-3                     [1, 128, 128, 128]        --\n",
      "│    │    └─Sequential: 3-2                   [1, 128, 128, 128]        295,680\n",
      "│    └─DownSampleBlock: 2-4                   [1, 128, 64, 64]          --\n",
      "│    │    └─Conv2d: 3-3                       [1, 128, 64, 64]          147,584\n",
      "│    └─ResidualBlock: 2-5                     [1, 128, 64, 64]          --\n",
      "│    │    └─Sequential: 3-4                   [1, 128, 64, 64]          295,680\n",
      "│    └─ResidualBlock: 2-6                     [1, 128, 64, 64]          --\n",
      "│    │    └─Sequential: 3-5                   [1, 128, 64, 64]          295,680\n",
      "│    └─DownSampleBlock: 2-7                   [1, 128, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-6                       [1, 128, 32, 32]          147,584\n",
      "│    └─ResidualBlock: 2-8                     [1, 256, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-7                       [1, 256, 32, 32]          33,024\n",
      "│    │    └─Sequential: 3-8                   [1, 256, 32, 32]          886,016\n",
      "│    └─ResidualBlock: 2-9                     [1, 256, 32, 32]          --\n",
      "│    │    └─Sequential: 3-9                   [1, 256, 32, 32]          1,181,184\n",
      "│    └─DownSampleBlock: 2-10                  [1, 256, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-10                      [1, 256, 16, 16]          590,080\n",
      "│    └─ResidualBlock: 2-11                    [1, 256, 16, 16]          --\n",
      "│    │    └─Sequential: 3-11                  [1, 256, 16, 16]          1,181,184\n",
      "│    └─ResidualBlock: 2-12                    [1, 256, 16, 16]          --\n",
      "│    │    └─Sequential: 3-12                  [1, 256, 16, 16]          1,181,184\n",
      "│    └─DownSampleBlock: 2-13                  [1, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-13                      [1, 256, 8, 8]            590,080\n",
      "│    └─ResidualBlock: 2-14                    [1, 512, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-14                      [1, 512, 8, 8]            131,584\n",
      "│    │    └─Sequential: 3-15                  [1, 512, 8, 8]            3,541,504\n",
      "│    └─NonLocalBlock: 2-15                    [1, 512, 8, 8]            262,656\n",
      "│    │    └─GroupNorm: 3-16                   [1, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-17                      [1, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-18                      [1, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-19                      [1, 512, 8, 8]            262,656\n",
      "│    └─ResidualBlock: 2-16                    [1, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-20                  [1, 512, 8, 8]            4,721,664\n",
      "│    └─NonLocalBlock: 2-17                    [1, 512, 8, 8]            262,656\n",
      "│    │    └─GroupNorm: 3-21                   [1, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-22                      [1, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-23                      [1, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-24                      [1, 512, 8, 8]            262,656\n",
      "│    └─ResidualBlock: 2-18                    [1, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-25                  [1, 512, 8, 8]            4,721,664\n",
      "│    └─NonLocalBlock: 2-19                    [1, 512, 8, 8]            262,656\n",
      "│    │    └─GroupNorm: 3-26                   [1, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-27                      [1, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-28                      [1, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-29                      [1, 512, 8, 8]            262,656\n",
      "│    └─ResidualBlock: 2-20                    [1, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-30                  [1, 512, 8, 8]            4,721,664\n",
      "│    └─GroupNorm: 2-21                        [1, 512, 8, 8]            --\n",
      "│    │    └─GroupNorm: 3-31                   [1, 512, 8, 8]            1,024\n",
      "│    └─Swish: 2-22                            [1, 512, 8, 8]            --\n",
      "│    └─Conv2d: 2-23                           [1, 256, 8, 8]            1,179,904\n",
      "===============================================================================================\n",
      "Total params: 29,295,872\n",
      "Trainable params: 29,295,872\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 17.18\n",
      "===============================================================================================\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 220.33\n",
      "Params size (MB): 114.03\n",
      "Estimated Total Size (MB): 334.43\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from torchinfo import summary\n",
    "\n",
    "enc = Encoder()\n",
    "c = enc(torch.randn(2, 1, 256, 256))\n",
    "\n",
    "print( 'The encoder architecture is'+'\\n{}'.format(\n",
    "    summary(enc,(1,1,128,128)) \n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder structure\n",
    "\n",
    "* Similar to encoder. Adding Upsampling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpSampleBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.interpolate(x, scale_factor=2.0)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, image_channels=1, latent_dim=256):\n",
    "        super(Decoder, self).__init__()\n",
    "        channels = [512, 256, 256, 128, 128]\n",
    "        attn_resolutions = [16]\n",
    "        num_res_blocks = 3\n",
    "        resolution = 16\n",
    "\n",
    "        in_channels = channels[0]\n",
    "        layers = [nn.Conv2d(latent_dim, in_channels, 3, 1, 1),\n",
    "                  ResidualBlock(in_channels, in_channels),\n",
    "                  NonLocalBlock(in_channels),\n",
    "                  ResidualBlock(in_channels, in_channels)]\n",
    "\n",
    "        for i in range(len(channels)):\n",
    "            out_channels = channels[i]\n",
    "            for j in range(num_res_blocks):\n",
    "                layers.append(ResidualBlock(in_channels, out_channels))\n",
    "                in_channels = out_channels\n",
    "                if resolution in attn_resolutions:\n",
    "                    layers.append(NonLocalBlock(in_channels))\n",
    "            if i != 0:\n",
    "                layers.append(UpSampleBlock(in_channels))\n",
    "                resolution *= 2\n",
    "\n",
    "        layers.append(GroupNorm(in_channels))\n",
    "        layers.append(Swish())\n",
    "        layers.append(nn.Conv2d(in_channels, image_channels, 3, 1, 1))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The encoder architecture is\n",
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "Decoder                                       [2, 1, 128, 128]          --\n",
      "├─Sequential: 1-1                             [2, 1, 128, 128]          --\n",
      "│    └─Conv2d: 2-1                            [2, 512, 8, 8]            1,180,160\n",
      "│    └─ResidualBlock: 2-2                     [2, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-1                   [2, 512, 8, 8]            4,721,664\n",
      "│    └─NonLocalBlock: 2-3                     [2, 512, 8, 8]            262,656\n",
      "│    │    └─GroupNorm: 3-2                    [2, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-3                       [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-4                       [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-5                       [2, 512, 8, 8]            262,656\n",
      "│    └─ResidualBlock: 2-4                     [2, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-6                   [2, 512, 8, 8]            4,721,664\n",
      "│    └─ResidualBlock: 2-5                     [2, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-7                   [2, 512, 8, 8]            4,721,664\n",
      "│    └─NonLocalBlock: 2-6                     [2, 512, 8, 8]            262,656\n",
      "│    │    └─GroupNorm: 3-8                    [2, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-9                       [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-10                      [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-11                      [2, 512, 8, 8]            262,656\n",
      "│    └─ResidualBlock: 2-7                     [2, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-12                  [2, 512, 8, 8]            4,721,664\n",
      "│    └─NonLocalBlock: 2-8                     [2, 512, 8, 8]            262,656\n",
      "│    │    └─GroupNorm: 3-13                   [2, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-14                      [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-15                      [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-16                      [2, 512, 8, 8]            262,656\n",
      "│    └─ResidualBlock: 2-9                     [2, 512, 8, 8]            --\n",
      "│    │    └─Sequential: 3-17                  [2, 512, 8, 8]            4,721,664\n",
      "│    └─NonLocalBlock: 2-10                    [2, 512, 8, 8]            262,656\n",
      "│    │    └─GroupNorm: 3-18                   [2, 512, 8, 8]            1,024\n",
      "│    │    └─Conv2d: 3-19                      [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-20                      [2, 512, 8, 8]            262,656\n",
      "│    │    └─Conv2d: 3-21                      [2, 512, 8, 8]            262,656\n",
      "│    └─ResidualBlock: 2-11                    [2, 256, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-22                      [2, 256, 8, 8]            131,328\n",
      "│    │    └─Sequential: 3-23                  [2, 256, 8, 8]            1,771,520\n",
      "│    └─NonLocalBlock: 2-12                    [2, 256, 8, 8]            65,792\n",
      "│    │    └─GroupNorm: 3-24                   [2, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-25                      [2, 256, 8, 8]            65,792\n",
      "│    │    └─Conv2d: 3-26                      [2, 256, 8, 8]            65,792\n",
      "│    │    └─Conv2d: 3-27                      [2, 256, 8, 8]            65,792\n",
      "│    └─ResidualBlock: 2-13                    [2, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-28                  [2, 256, 8, 8]            1,181,184\n",
      "│    └─NonLocalBlock: 2-14                    [2, 256, 8, 8]            65,792\n",
      "│    │    └─GroupNorm: 3-29                   [2, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-30                      [2, 256, 8, 8]            65,792\n",
      "│    │    └─Conv2d: 3-31                      [2, 256, 8, 8]            65,792\n",
      "│    │    └─Conv2d: 3-32                      [2, 256, 8, 8]            65,792\n",
      "│    └─ResidualBlock: 2-15                    [2, 256, 8, 8]            --\n",
      "│    │    └─Sequential: 3-33                  [2, 256, 8, 8]            1,181,184\n",
      "│    └─NonLocalBlock: 2-16                    [2, 256, 8, 8]            65,792\n",
      "│    │    └─GroupNorm: 3-34                   [2, 256, 8, 8]            512\n",
      "│    │    └─Conv2d: 3-35                      [2, 256, 8, 8]            65,792\n",
      "│    │    └─Conv2d: 3-36                      [2, 256, 8, 8]            65,792\n",
      "│    │    └─Conv2d: 3-37                      [2, 256, 8, 8]            65,792\n",
      "│    └─UpSampleBlock: 2-17                    [2, 256, 16, 16]          --\n",
      "│    │    └─Conv2d: 3-38                      [2, 256, 16, 16]          590,080\n",
      "│    └─ResidualBlock: 2-18                    [2, 256, 16, 16]          --\n",
      "│    │    └─Sequential: 3-39                  [2, 256, 16, 16]          1,181,184\n",
      "│    └─ResidualBlock: 2-19                    [2, 256, 16, 16]          --\n",
      "│    │    └─Sequential: 3-40                  [2, 256, 16, 16]          1,181,184\n",
      "│    └─ResidualBlock: 2-20                    [2, 256, 16, 16]          --\n",
      "│    │    └─Sequential: 3-41                  [2, 256, 16, 16]          1,181,184\n",
      "│    └─UpSampleBlock: 2-21                    [2, 256, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-42                      [2, 256, 32, 32]          590,080\n",
      "│    └─ResidualBlock: 2-22                    [2, 128, 32, 32]          --\n",
      "│    │    └─Conv2d: 3-43                      [2, 128, 32, 32]          32,896\n",
      "│    │    └─Sequential: 3-44                  [2, 128, 32, 32]          443,392\n",
      "│    └─ResidualBlock: 2-23                    [2, 128, 32, 32]          --\n",
      "│    │    └─Sequential: 3-45                  [2, 128, 32, 32]          295,680\n",
      "│    └─ResidualBlock: 2-24                    [2, 128, 32, 32]          --\n",
      "│    │    └─Sequential: 3-46                  [2, 128, 32, 32]          295,680\n",
      "│    └─UpSampleBlock: 2-25                    [2, 128, 64, 64]          --\n",
      "│    │    └─Conv2d: 3-47                      [2, 128, 64, 64]          147,584\n",
      "│    └─ResidualBlock: 2-26                    [2, 128, 64, 64]          --\n",
      "│    │    └─Sequential: 3-48                  [2, 128, 64, 64]          295,680\n",
      "│    └─ResidualBlock: 2-27                    [2, 128, 64, 64]          --\n",
      "│    │    └─Sequential: 3-49                  [2, 128, 64, 64]          295,680\n",
      "│    └─ResidualBlock: 2-28                    [2, 128, 64, 64]          --\n",
      "│    │    └─Sequential: 3-50                  [2, 128, 64, 64]          295,680\n",
      "│    └─UpSampleBlock: 2-29                    [2, 128, 128, 128]        --\n",
      "│    │    └─Conv2d: 3-51                      [2, 128, 128, 128]        147,584\n",
      "│    └─GroupNorm: 2-30                        [2, 128, 128, 128]        --\n",
      "│    │    └─GroupNorm: 3-52                   [2, 128, 128, 128]        256\n",
      "│    └─Swish: 2-31                            [2, 128, 128, 128]        --\n",
      "│    └─Conv2d: 2-32                           [2, 1, 128, 128]          1,153\n",
      "===============================================================================================\n",
      "Total params: 41,026,305\n",
      "Trainable params: 41,026,305\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 23.04\n",
      "===============================================================================================\n",
      "Input size (MB): 0.13\n",
      "Forward/backward pass size (MB): 249.82\n",
      "Params size (MB): 159.11\n",
      "Estimated Total Size (MB): 409.07\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "dnc = Decoder()\n",
    "c = dnc(torch.randn(2, 256, 8, 8))\n",
    "\n",
    "print( 'The encoder architecture is'+'\\n{}'.format(\n",
    "    summary(dnc,(2,256,8,8)) \n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnm-old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
