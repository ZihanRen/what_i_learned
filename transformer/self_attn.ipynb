{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-head self attention\n",
    "\n",
    "[code source](https://peterbloem.nl/blog/transformers)\n",
    "\n",
    "* each attention head (k) is a chunk of input dimension (k). Multihead attention outputs (k//h) are aggregated into the original shape of input - this is just a more efficient way of calculating multi-head attention\n",
    "* x' = attention (x), where x and x' share the same dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, k, heads=4, mask=False):\n",
    "        super().__init__()\n",
    "        assert k % heads == 0\n",
    "        self.k, self.heads = k, heads\n",
    "        # since key, query and value similarity are all same and characterized using product, \n",
    "        # thus they share the same dimension\n",
    "        self.tokeys = nn.Linear(k, k, bias=False)\n",
    "        self.toqueries = nn.Linear(k, k, bias=False)\n",
    "        self.tovalues = nn.Linear(k, k, bias=False)\n",
    "        self.unifyheads = nn.Linear(k, k)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Example input shape: (batch_size=2, sequence_length=10, k=6)\n",
    "        print(\"Input shape:\", x.shape)\n",
    "\n",
    "        b, t, k = x.size() # t represents sequence length, k represents sequence dimension\n",
    "        h = self.heads\n",
    "\n",
    "        queries = self.toqueries(x)\n",
    "        keys = self.tokeys(x)\n",
    "        print(f'keys vector after linear transformation: {keys.size()}') # (4,10,3)\n",
    "        print(\"Weight shape:\", self.toqueries.weight.shape)\n",
    "\n",
    "\n",
    "        values = self.tovalues(x)\n",
    "\n",
    "        s = k // h\n",
    "\n",
    "        keys = keys.view(b, t, h, s).transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "        queries = queries.view(b, t, h, s).transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "        values = values.view(b, t, h, s).transpose(1, 2).contiguous().view(b * h, t, s)\n",
    "\n",
    "        # Example weight shape: (k=6, k=6)\n",
    "        print(f'keys vector shape after adding multiple attension heads is: {keys.size()}') # (4,10,3)\n",
    "\n",
    "        queries = queries\n",
    "        keys = keys\n",
    "\n",
    "        dot = torch.bmm(queries, keys.transpose(1, 2))\n",
    "        # Example dot shape: (batch_size=2, heads=4, sequence_length=10, sequence_length=10)\n",
    "        print(\"Dot product shape:\", dot.shape)\n",
    "\n",
    "        dot = dot / (k ** (1/2))\n",
    "\n",
    "        dot = F.softmax(dot, dim=2)\n",
    "        print(f'Softmax dot product shape is {dot.shape}')\n",
    "\n",
    "        out = torch.bmm(dot, values).view(b, h, t, s)\n",
    "        out = out.transpose(1, 2).contiguous().view(b, t, s * h)\n",
    "\n",
    "        # Example output shape: (batch_size=2, sequence_length=10, k=6)\n",
    "        print(\"Output shape:\", self.unifyheads(out).shape)\n",
    "\n",
    "        return self.unifyheads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 10, 6])\n",
      "keys vector after linear transformation: torch.Size([2, 10, 6])\n",
      "Weight shape: torch.Size([6, 6])\n",
      "keys vector shape after adding multiple attension heads is: torch.Size([4, 10, 3])\n",
      "Dot product shape: torch.Size([4, 10, 10])\n",
      "Softmax dot product shape is torch.Size([4, 10, 10])\n",
      "Output shape: torch.Size([2, 10, 6])\n",
      "torch.Size([2, 10, 6])\n"
     ]
    }
   ],
   "source": [
    "# Example input tensor\n",
    "# sequence dimension=6. sequence length = 10\n",
    "x = torch.randn(2, 10, 6)\n",
    "\n",
    "# Create an instance of the SelfAttention class with k=6 and heads=2\n",
    "self_attention = SelfAttention(6, 2)\n",
    "\n",
    "# Pass the input tensor to the forward method\n",
    "output = self_attention(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "* input x with size (batch,seq_len,seq_dim)\n",
    "* linear transformation matrix (query,key,values) with size (seq_dim,seq_dim). Transform input sequence to the matrix with the same shape\n",
    "* Adding multiple heads: reshape the matrix into different components. Each component represents one head\n",
    "* Query * keys = (batch,seq_len,seq_len): a matrix contains all similarity beteen each sequence. attention matrix\n",
    "* attention matrix mulitiplied by values: get the final attension score. The final attention score is the same shape as input. But now it's a overall vector combines all importance information in different sequence parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnm-old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
